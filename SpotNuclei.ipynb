{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import imgaug.augmenters as augmenters\n",
    "\n",
    "import samples.nucleus\n",
    "\n",
    "import keras.backend\n",
    "\n",
    "K = keras.backend.backend()\n",
    "if K=='tensorflow':\n",
    "    keras.backend.set_image_dim_ordering('tf')\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "CLUSTER_BASE = os.path.join(ROOT_DIR, \"../clusters\") \n",
    "\n",
    "with open(os.path.join(CLUSTER_BASE, 'all_files.pk'), 'rb') as f:\n",
    "    FILE_LIST = pickle.load(f)\n",
    "    \n",
    "FILE_LIST = [os.path.join(CLUSTER_BASE, f) for f in FILE_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BalancedNucleiDataset(utils.Dataset):\n",
    "    \n",
    "    def prepare(self):\n",
    "        self.name = \"nuclei\"\n",
    "        self.add_class(self.name, 1, \"nucleus\")\n",
    "        for i, basePath in enumerate(FILE_LIST):\n",
    "            imgRef = os.path.basename(basePath)\n",
    "            self.add_image(self.name, image_id=i, \n",
    "                           path=basePath+'.png',\n",
    "                           maskPath=glob.glob(basePath + '/*.png'),\n",
    "                           img_ref=imgRef)\n",
    "        super().prepare()\n",
    "        \n",
    "    def load_image(self, image_id):\n",
    "        image = skimage.io.imread(self.image_info[image_id]['path'])[:,:,:3]\n",
    "        return image\n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == self.name:\n",
    "            return info['img_ref']\n",
    "        else:\n",
    "            return super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        masks = np.dstack([skimage.io.imread(f) for f in self.image_info[image_id]['maskPath']])\n",
    "        return masks, np.repeat(1, masks.shape[-1])\n",
    "    \n",
    "def getDatasets(cvPart):\n",
    "    dataset_train = BalancedNucleiDataset()\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    dataset_val = BalancedNucleiDataset()\n",
    "    dataset_val.prepare()\n",
    "    return dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1379, 1379)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No real validation set for now - it gets little tricky given that:\n",
    "# 1. In pre-processing data is clustered and balanced by clusters. \n",
    "# 2. While training there are random augmentations\n",
    "\n",
    "dataset_train, dataset_val =getDatasets(9)\n",
    "len(dataset_train.image_info), len(dataset_val.image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                2.0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [ 43.53287505  39.56061986  48.22454996]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           nucleus\n",
      "NUM_CLASSES                    2\n",
      "OPTIMIZER                      SGD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                1379\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NucleusConfig1(nucleus.NucleusConfig):\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    OPTIMIZER = 'SGD'\n",
    "    STEPS_PER_EPOCH = len(dataset_train.image_info)\n",
    "    VALIDATION_STEPS = 100\n",
    "    MEAN_PIXEL = np.array([43.53287505,   39.56061986,   48.22454996]) \n",
    "    BACKBONE = \"resnet50\"\n",
    "    \n",
    "config = NucleusConfig1()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmentation = augmenters.OneOf([\n",
    "                    augmenters.Fliplr(1),\n",
    "                    augmenters.Flipud(1),\n",
    "                    augmenters.Affine(rotate=90),\n",
    "                    augmenters.Affine(rotate=-90),\n",
    "                    augmenters.Sequential([\n",
    "                        augmenters.Affine(shear=(-8,8)),\n",
    "                        augmenters.Crop(percent=0.05)\n",
    "                    ])\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last()[1], by_name=True)\n",
    "    print(\"Loaded \", model.find_last()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=5, \n",
    "            layers='heads',\n",
    "            augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    for f in sorted(glob.glob(MODEL_DIR + '/nucleus*/mask_rcnn_acnd_*'))[:-1]:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanup()\n",
    "model.train(dataset_train, dataset_val, \n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        epochs=10, \n",
    "        layers=\"all\",\n",
    "        augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanup()\n",
    "model.train(dataset_train, dataset_val, \n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        epochs=10, \n",
    "        layers=\"all\",\n",
    "        augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.config.OPTIMIZER = 'Adam'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
